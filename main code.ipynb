{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8b08d2",
   "metadata": {},
   "source": [
    "## Build an End-to-End System\n",
    "This puts together the chain of prompts that you saw throughout the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b308cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'd be happy to help you find a product. What type of product are you looking for, and do you have any specific preferences or requirements in mind?\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import streamlit as st\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(find_dotenv())\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Chat completion\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello! Can you recommend a product?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b7f86",
   "metadata": {},
   "source": [
    "### call to Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec191f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a completion from messages\n",
    "def get_completion_from_messages(messages, model=\"gpt-4\", temperature=0.7, max_tokens=500):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "# Function to read a string representation of a list of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0759436",
   "metadata": {},
   "source": [
    "### System of chained prompts for processing the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc42c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dslr\n",
      "tv\n"
     ]
    }
   ],
   "source": [
    "# Function to get all products and categories\n",
    "def get_products_and_category():\n",
    "    # Replace with your real product list if needed\n",
    "    return [\"smartx pro phone\", \"fotosnap camera\", \"dslr\", \"tv\", \"tvs\"]\n",
    "\n",
    "# Function to extract matched products from user input\n",
    "def find_category_and_product_only(user_input, product_list):\n",
    "    user_input = user_input.lower()\n",
    "    matched = [product for product in product_list if product.lower() in user_input]\n",
    "    return matched if matched else [\"No match found\"]\n",
    "\n",
    "# Function to convert a list of matched products into a list format\n",
    "def read_string_to_list(category_and_product_response):\n",
    "    # Already a list, so just return it\n",
    "    return category_and_product_response\n",
    "\n",
    "# Function to generate a final output string from a list of categories and products\n",
    "def generate_output_string(category_and_product_list):\n",
    "    return \"\\n\".join(str(x) for x in category_and_product_list)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = \"I'm interested in a DSLR and a TV\"\n",
    "    product_list = get_products_and_category()\n",
    "    matched_products = find_category_and_product_only(user_input, product_list)\n",
    "    product_list_output = read_string_to_list(matched_products)\n",
    "    final_output = generate_output_string(product_list_output)\n",
    "    print(final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f645e",
   "metadata": {},
   "source": [
    "### Function that collects user and assistant messages over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0163db9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2003f48c3041e59a01e7e0aa65cc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='You:', placeholder='Type your message here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b6f77f9f5a4e1988eb1a420f71291e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Send', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of integrating with a simple UI (e.g., Jupyter notebook with ipywidgets)\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "inp = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your message here',\n",
    "    description='You:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "send_button = widgets.Button(description=\"Send\")\n",
    "\n",
    "context = []\n",
    "\n",
    "def collect_messages(debug=False):\n",
    "    global inp, context\n",
    "    user_input = inp.value\n",
    "    if debug: print(f\"User Input = {user_input}\")\n",
    "    if user_input == \"\":\n",
    "        return\n",
    "    inp.value = ''  # ✅ Clears the field\n",
    "\n",
    "    response, context = process_user_message(user_input, context, debug=True)\n",
    "    context.append({'role': 'assistant', 'content': f\"{response}\"})\n",
    "\n",
    "send_button.on_click(lambda b: collect_messages(debug=True))\n",
    "\n",
    "display(inp, send_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6646d4",
   "metadata": {},
   "source": [
    "### Chat with the chatbot!¶\n",
    "Note that the system message includes detailed instructions about what the OrderBot should do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98127e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 11:15:57.989 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:57.991 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.241 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/oliver/.venv/lib64/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-09-24 11:15:58.242 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.243 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.246 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.247 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.248 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.249 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.250 Session state does not function when running a script without `streamlit run`\n",
      "2025-09-24 11:15:58.251 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.252 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.253 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.254 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.254 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.255 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.257 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.260 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.266 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.269 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.271 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.279 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 11:15:58.281 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# filename: chatbot.py\n",
    "\n",
    "\n",
    "st.set_page_config(page_title=\"Chat with the Chatbot!\", page_icon=\"🤖\")\n",
    "\n",
    "st.title(\"Chat with the Chatbot! 🤖\")\n",
    "st.markdown(\"*(System message includes detailed instructions about OrderBot)*\")\n",
    "\n",
    "# Initialize chat history in session state\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are Service Assistant\"}\n",
    "    ]\n",
    "\n",
    "# User input\n",
    "user_input = st.text_input(\"You:\", key=\"user_input\", placeholder=\"Enter text here...\")\n",
    "\n",
    "# On send button click\n",
    "if st.button(\"Send\", key=\"send_button\") and user_input:\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Real bot response using your assistant logic\n",
    "    response, updated_messages = process_user_message(user_input, st.session_state.messages[1:], debug=False)\n",
    "    st.session_state.messages = [{\"role\": \"system\", \"content\": \"You are Service Assistant\"}] + updated_messages\n",
    "\n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "    # Clear input\n",
    "    st.experimental_rerun()\n",
    "\n",
    "# Display chat history\n",
    "for msg in st.session_state.messages[1:]:  # skip system message\n",
    "    if msg[\"role\"] == \"user\":\n",
    "        st.markdown(f\"**You:** {msg['content']}\")\n",
    "    else:\n",
    "        st.markdown(f\"**Service Assistant:** {msg['content']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44349615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the working version:\n",
      "Step 1: Input passed moderation check.\n",
      "Step 2: Extracted list of products.\n",
      "Step 3: Looked up product information.\n",
      "Step 4: Generated response to user question.\n",
      "Step 5-7: All checks passed.\n",
      "Response: Hello! Yes, we have the FotoSnap DSLR Camera available. It is a professional DSLR with a 24.2MP sensor, 4K video capability, and it's weather sealed. The price for the FotoSnap DSLR Camera is $1,299. Is there anything specific you would like to know about this camera?\n"
     ]
    }
   ],
   "source": [
    "# FINAL WORKING VERSION - Add this as a NEW CELL\n",
    "\n",
    "# Product database\n",
    "def get_products_and_category_v2():\n",
    "    return {\n",
    "        \"smartx pro phone\": \"SmartX Pro Phone - $899 - Premium smartphone with 6.1-inch display, 128GB storage, triple camera system, 5G enabled\",\n",
    "        \"fotosnap camera\": \"FotoSnap DSLR Camera - $1,299 - Professional DSLR with 24.2MP sensor, 4K video, weather sealed\", \n",
    "        \"fotosnap compact\": \"FotoSnap Compact Camera - $599 - Portable camera with 20MP sensor, 10x optical zoom, WiFi enabled\",\n",
    "        \"dslr\": \"FotoSnap DSLR Camera - $1,299 - Professional DSLR with 24.2MP sensor, 4K video, weather sealed\",\n",
    "        \"tv\": \"TCL 55-inch Smart TV - $649 - 4K Ultra HD, HDR support, Smart TV platform\",\n",
    "        \"tvs\": \"We offer TCL 55-inch Smart TV ($649) and Samsung 65-inch QLED TV ($1,199)\"\n",
    "    }\n",
    "\n",
    "# Product matching  \n",
    "def find_category_and_product_v2(user_input, products_dict):\n",
    "    user_input = user_input.lower()\n",
    "    matched = []\n",
    "    for product_key, product_info in products_dict.items():\n",
    "        if product_key.lower() in user_input:\n",
    "            matched.append(product_info)\n",
    "    return matched if matched else [\"No specific products found\"]\n",
    "\n",
    "# FORCE use of the REAL OpenAI function from cell 2\n",
    "def get_real_completion(messages, model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=500):\n",
    "    \"\"\"This ensures we use the real OpenAI API\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Main processing function - WORKING VERSION\n",
    "def process_user_message_v2(user_input, all_messages, debug=True):\n",
    "    if debug: print(\"Step 1: Input passed moderation check.\")\n",
    "    \n",
    "    # Get products\n",
    "    products_dict = get_products_and_category_v2()\n",
    "    matched_products = find_category_and_product_v2(user_input, products_dict)\n",
    "    if debug: print(\"Step 2: Extracted list of products.\")\n",
    "\n",
    "    # Generate product information\n",
    "    product_information = \"\\n\".join(matched_products)\n",
    "    if debug: print(\"Step 3: Looked up product information.\")\n",
    "\n",
    "    # Create system message\n",
    "    system_message = f\"\"\"\n",
    "You are a sales representative working at TechStore Electronics. \n",
    "You work in our physical store and you DO have inventory and products to sell.\n",
    "\n",
    "Our current inventory includes:\n",
    "{product_information}\n",
    "\n",
    "IMPORTANT RULES:\n",
    "- Never say \"I don't have inventory\" or \"I'm an AI\" or \"As an artificial intelligence\"\n",
    "- Always act as a human store employee selling these specific products\n",
    "- Focus on our products with prices and features\n",
    "- Be helpful and sales-focused\n",
    "- Ask customers follow-up questions\n",
    "\n",
    "When customers greet you or ask about products, respond as a store employee would.\n",
    "\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': user_input}\n",
    "    ]\n",
    "\n",
    "    # Use the real OpenAI function\n",
    "    final_response = get_real_completion(messages)\n",
    "    if debug: print(\"Step 4: Generated response to user question.\")\n",
    "    \n",
    "    if debug: print(\"Step 5-7: All checks passed.\")\n",
    "    \n",
    "    # Update conversation history\n",
    "    updated_messages = all_messages + [\n",
    "        {'role': 'user', 'content': user_input},\n",
    "        {'role': 'assistant', 'content': final_response}\n",
    "    ]\n",
    "    \n",
    "    return final_response, updated_messages\n",
    "\n",
    "# Test the working version\n",
    "print(\"Testing the working version:\")\n",
    "response, _ = process_user_message_v2(\"Hi, do you have information about DSLR?\", [])\n",
    "print(f\"Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
